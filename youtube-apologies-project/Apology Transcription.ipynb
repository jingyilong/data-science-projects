{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c091d490",
   "metadata": {},
   "source": [
    "# YouTube Apology Transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da6781",
   "metadata": {},
   "source": [
    "This notebook shows the transcription process of videos from this [YouTube playlist][]. **It does not need to be run.** \n",
    "\n",
    "Final results can be found in \"apology_transcript.csv\".\n",
    "\n",
    "Running this notebook requires downloading the playlist as mp3 files and renaming them based on the IDs determined from [this spreadsheet](https://docs.google.com/spreadsheets/d/1zewXF_WeSIH3QBlW4c5MMv7hBsBAc8cOhAaG4aBBuKM/edit?usp=sharing). Some videos deleted from YouTube were retrieved from the Internet Archive and other locations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1156e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTED LIBRARIES -- Run this\n",
    "\n",
    "# Libraries for apology transcription\n",
    "import pandas as pd\n",
    "import whisper\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d170ca",
   "metadata": {},
   "source": [
    "# Whisper Installation (only run once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b0581",
   "metadata": {},
   "source": [
    "[Whisper](https://openai.com/research/whisper) is an open source speech recognition software from OpenAI. We are using Whisper to automate the transcription process of the apology videos as we cannot watch and transcribe all the videos ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a58de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installs OpenAi's Whisper speech-recognition model \n",
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd7c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installs rust\n",
    "!pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4adae6",
   "metadata": {},
   "source": [
    "# Data Intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intakes CSV file as a dataframe\n",
    "apology_info_df = pd.read_csv('100_YT_Sheet.csv')\n",
    "\n",
    "# Deletes rows that do not have an ID\n",
    "apology_info_df = apology_info_df.dropna(subset=['ID'])\n",
    "\n",
    "# Transforms date posted column into numerical dates\n",
    "apology_info_df['Date Posted'] = pd.to_datetime(apology_info_df['Date Posted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf3a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apology_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc130bb8",
   "metadata": {},
   "source": [
    "# Initial Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62dc45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS BLOCK ONCE -- DO NOT RUN IF YOU HAVE ALREADY ADDED APOLOGIES TO THE LIST, THIS WILL ERASE THEM\n",
    "# Creates a list to store apology transcripts\n",
    "apology_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74101c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that transcribes files using Whisper \n",
    "def transcribeAudio(audioFile, youtuber_id): \n",
    "    # Loads Whisper to transcribe the audio\n",
    "    model = whisper.load_model(\"base\")\n",
    "    apology_file = Path(audioFile)\n",
    "    # Checks if file is present in the directory and begins transcription if it is\n",
    "    if apology_file.is_file()==True:\n",
    "        result = model.transcribe(audioFile)\n",
    "        #Appends the transcription to the apology list along with the YouTuber ID\n",
    "        transcript = dict(ID=youtuber_id, Transcript=result[\"text\"])\n",
    "        apology_list.append(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7d847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creates a list of apology IDs from the IDs in the apology dataframe\n",
    "apology_ids = apology_info_df[\"ID\"]\n",
    "\n",
    "# Transcribes apologies of YouTubers present in the apology ID list\n",
    "for youtuber in apology_ids:\n",
    "    count = 0\n",
    "    transcibed = 0\n",
    "    # Iterates through apologies list to check if the apology was already transcribed\n",
    "    for apology in apology_list:\n",
    "        if youtuber in apology_list[count]['ID']:\n",
    "            transcibed = 1\n",
    "            #print (\"Transcription done: \", youtuber)\n",
    "        count += 1\n",
    "    # Transcribes the apology if it is not in the list\n",
    "    if  transcibed == 0:\n",
    "        transcribeAudio(youtuber+\".mp3\", youtuber)\n",
    "        print (youtuber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3897180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that exports the dataframe of apologies into a CSV file for further manipulation\n",
    "def exportApologies (exportList, exportDF):\n",
    "    # Converts the list into a dataframe and exports it as a csv file    \n",
    "    exportDF = pd.DataFrame.from_dict(exportList)\n",
    "    exportDF.to_csv('apology_transcript.csv')\n",
    "    \n",
    "    # Exports transcripts into text files\n",
    "    count = 0\n",
    "    for apology in exportList:\n",
    "        fileName = exportList[count]['ID']+\".txt\"\n",
    "        transcript = exportList[count]['Transcript']\n",
    "        with open(fileName, 'w') as output:\n",
    "            output.write(transcript)\n",
    "        output.close()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6805858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports the dataframe of apology transcriptions into a CSV file\n",
    "exportApologies (apology_list, apology_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b7378",
   "metadata": {},
   "source": [
    "# Transcription based on missing apologies in apology_transcript.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab34879b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ts/9x8sw2z502vcqq0v__1pg46c0000gn/T/ipykernel_1568/2818201959.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapology_info_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'100 YT rework.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mapology_transcripts_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apology_transcript.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Imports CSV of apology metadata and CSV of transcribed apology\n",
    "apology_info_df = pd.read_csv('100 YT rework.csv')\n",
    "apology_transcripts_df = pd.read_csv('apology_transcript.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab66ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for apology IDs that need to be transcribed\n",
    "apologiesToDo = []\n",
    "\n",
    "count = 0\n",
    "transcription = 0\n",
    "\n",
    "# Goes through every apology in the CSV and checks if it present in the apology transcipt dataframe\n",
    "# If it is not, the apology ID is added to a list \n",
    "for apology in apology_info_df.index: #100 youtubers\n",
    "    ID = (apology_info_df.loc[count]['ID'])\n",
    "    \n",
    "    count2 = 0\n",
    "    for index in apology_transcripts_df.index:\n",
    "        #ID = apology_transcripts_df.loc[index,'ID']\n",
    "        if ID in apology_transcripts_df.loc[count2]['ID']:\n",
    "            transcription = 1\n",
    "        count2+=1\n",
    "    if transcription == 0:\n",
    "        apologiesToDo.append(ID) # Adds ID if it has not been transcribed\n",
    "    transcription = 0\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eec39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "apologiesToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba064f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transcribes the remaining apologies\n",
    "for ID in apologiesToDo:\n",
    "    transcribeAudio(ID+\".mp3\", ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b95264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports dataframe into a CSV file\n",
    "exportApologies (apology_list, apology_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
